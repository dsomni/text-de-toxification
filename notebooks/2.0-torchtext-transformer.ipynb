{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text detoxification using Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:44.873357Z",
     "iopub.status.busy": "2023-10-30T15:45:44.873056Z",
     "iopub.status.idle": "2023-10-30T15:45:50.512221Z",
     "shell.execute_reply": "2023-10-30T15:45:50.511415Z",
     "shell.execute_reply.started": "2023-10-30T15:45:44.873330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.514346Z",
     "iopub.status.busy": "2023-10-30T15:45:50.513886Z",
     "iopub.status.idle": "2023-10-30T15:45:50.522654Z",
     "shell.execute_reply": "2023-10-30T15:45:50.521758Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.514319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MANUAL_SEED = 42\n",
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.524040Z",
     "iopub.status.busy": "2023-10-30T15:45:50.523804Z",
     "iopub.status.idle": "2023-10-30T15:45:50.639351Z",
     "shell.execute_reply": "2023-10-30T15:45:50.638450Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.524019Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df)=28462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Come on, Cal, leave that shit alone.</td>\n",
       "      <td>come on, Cal, put it down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like that shit.</td>\n",
       "      <td>I love it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hey, leave the poor bastard alone!</td>\n",
       "      <td>leave the poor man alone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Now, I understand you got your grievances with...</td>\n",
       "      <td>I understand you don't have to cut your bills,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               toxic  \\\n",
       "0  They're all laughing at us, so we'll kick your...   \n",
       "1               Come on, Cal, leave that shit alone.   \n",
       "2                                  I like that shit.   \n",
       "3                 Hey, leave the poor bastard alone!   \n",
       "4  Now, I understand you got your grievances with...   \n",
       "\n",
       "                                            nontoxic  \n",
       "0            they're laughing at us. We'll show you.  \n",
       "1                         come on, Cal, put it down.  \n",
       "2                                         I love it.  \n",
       "3                          leave the poor man alone!  \n",
       "4  I understand you don't have to cut your bills,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/dataset_md.csv\")\n",
    "print(f\"{len(df)=}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.641795Z",
     "iopub.status.busy": "2023-10-30T15:45:50.641453Z",
     "iopub.status.idle": "2023-10-30T15:45:50.657314Z",
     "shell.execute_reply": "2023-10-30T15:45:50.656463Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.641767Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(test_df)=500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's feeding time at the fucking zoo!</td>\n",
       "      <td>it's time to eat at the zoo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone here bet on the hero and lost their a...</td>\n",
       "      <td>they all took a hero and lost everything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then I got to come home to Melvin and his bull...</td>\n",
       "      <td>then I'm going home and Melvin's there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sara here was hoping to pick your brains.</td>\n",
       "      <td>Sara was hoping you could handle her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, that's stupid. If anyone wants to tell me ...</td>\n",
       "      <td>if anyone wants to tell me what's going on, I'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               toxic  \\\n",
       "0              It's feeding time at the fucking zoo!   \n",
       "1  Everyone here bet on the hero and lost their a...   \n",
       "2  Then I got to come home to Melvin and his bull...   \n",
       "3          Sara here was hoping to pick your brains.   \n",
       "4  Oh, that's stupid. If anyone wants to tell me ...   \n",
       "\n",
       "                                            nontoxic  \n",
       "0                       it's time to eat at the zoo!  \n",
       "1          they all took a hero and lost everything.  \n",
       "2            then I'm going home and Melvin's there.  \n",
       "3              Sara was hoping you could handle her.  \n",
       "4  if anyone wants to tell me what's going on, I'...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/raw/test.csv\")\n",
    "print(f\"{len(test_df)=}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:45:50.659272Z",
     "iopub.status.busy": "2023-10-30T15:45:50.658672Z",
     "iopub.status.idle": "2023-10-30T15:46:04.091748Z",
     "shell.execute_reply": "2023-10-30T15:46:04.090684Z",
     "shell.execute_reply.started": "2023-10-30T15:45:50.659237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "SPECIAL_SYMBOLS = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "TOKENIZER = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:04.094446Z",
     "iopub.status.busy": "2023-10-30T15:46:04.093174Z",
     "iopub.status.idle": "2023-10-30T15:46:04.105119Z",
     "shell.execute_reply": "2023-10-30T15:46:04.104195Z",
     "shell.execute_reply.started": "2023-10-30T15:46:04.094407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DetoxificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self._preprocess()\n",
    "        self._create_vocab()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        # Clean columns\n",
    "        self.df[\"toxic\"] = self.df[\"toxic\"].str.lower()\n",
    "        self.df[\"nontoxic\"] = self.df[\"nontoxic\"].str.lower()\n",
    "\n",
    "        # Tokenize sentences\n",
    "        self.toxic = self.df[\"toxic\"].apply(TOKENIZER).to_list()\n",
    "        self.nontoxic = self.df[\"nontoxic\"].apply(TOKENIZER).to_list()\n",
    "\n",
    "        self.data = self.toxic + self.nontoxic\n",
    "\n",
    "    def _create_vocab(self):\n",
    "        self.vocab = build_vocab_from_iterator(\n",
    "            self.data,\n",
    "            min_freq=1,\n",
    "            specials=SPECIAL_SYMBOLS,\n",
    "            special_first=True,\n",
    "        )\n",
    "        self.vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "    def _get_toxic(self, index: int) -> list:\n",
    "        text = self.toxic[index]\n",
    "        return [BOS_IDX] + self.vocab(text) + [EOS_IDX]\n",
    "\n",
    "    def _get_nontoxic(self, index: int) -> list:\n",
    "        text = self.nontoxic[index]\n",
    "        return [BOS_IDX] + self.vocab(text) + [EOS_IDX]\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[list, list]:\n",
    "        return self._get_toxic(index), self._get_nontoxic(index)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:04.106997Z",
     "iopub.status.busy": "2023-10-30T15:46:04.106618Z",
     "iopub.status.idle": "2023-10-30T15:46:07.777044Z",
     "shell.execute_reply": "2023-10-30T15:46:07.775971Z",
     "shell.execute_reply.started": "2023-10-30T15:46:04.106969Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = DetoxificationDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.781101Z",
     "iopub.status.busy": "2023-10-30T15:46:07.780816Z",
     "iopub.status.idle": "2023-10-30T15:46:07.811091Z",
     "shell.execute_reply": "2023-10-30T15:46:07.810236Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.781077Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset)=27039\n",
      "len(val_dataset)=1423\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [0.95, 0.05], generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    ")\n",
    "print(f\"{len(train_dataset)=}\")\n",
    "print(f\"{len(val_dataset)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.812402Z",
     "iopub.status.busy": "2023-10-30T15:46:07.812119Z",
     "iopub.status.idle": "2023-10-30T15:46:07.816776Z",
     "shell.execute_reply": "2023-10-30T15:46:07.815820Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.812377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "MAX_SIZE = 100\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.820703Z",
     "iopub.status.busy": "2023-10-30T15:46:07.820331Z",
     "iopub.status.idle": "2023-10-30T15:46:07.830576Z",
     "shell.execute_reply": "2023-10-30T15:46:07.829731Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.820679Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.831643Z",
     "iopub.status.busy": "2023-10-30T15:46:07.831399Z",
     "iopub.status.idle": "2023-10-30T15:46:07.842123Z",
     "shell.execute_reply": "2023-10-30T15:46:07.841338Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.831622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch: list) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    toxic_batch, nontoxic_batch = [], []\n",
    "    for _toxic, _nontoxic in batch:\n",
    "        _toxic_tensor = torch.Tensor(_toxic)\n",
    "        _nontoxic_tensor = torch.Tensor(_nontoxic)\n",
    "\n",
    "        toxic_batch.append(_toxic_tensor[:MAX_SIZE])\n",
    "        nontoxic_batch.append(_nontoxic_tensor[:MAX_SIZE])\n",
    "\n",
    "    toxic_batch = pad_sequence(toxic_batch, padding_value=PAD_IDX)\n",
    "    nontoxic_batch = pad_sequence(nontoxic_batch, padding_value=PAD_IDX)\n",
    "\n",
    "    return toxic_batch.long(), nontoxic_batch.long()\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.844380Z",
     "iopub.status.busy": "2023-10-30T15:46:07.843256Z",
     "iopub.status.idle": "2023-10-30T15:46:07.919445Z",
     "shell.execute_reply": "2023-10-30T15:46:07.918458Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.844355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 128])\n",
      "torch.Size([49, 128])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    inp, out = batch\n",
    "    print(inp.shape)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.921039Z",
     "iopub.status.busy": "2023-10-30T15:46:07.920762Z",
     "iopub.status.idle": "2023-10-30T15:46:07.948728Z",
     "shell.execute_reply": "2023-10-30T15:46:07.947826Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.921015Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
       "         [874, 118,  18,  ..., 284, 114,  85],\n",
       "         [ 10,  22,  27,  ...,   8,  15,  69],\n",
       "         ...,\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1],\n",
       "         [  1,   1,   1,  ...,   1,   1,   1]]),\n",
       " tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
       "         [4165,   20,   18,  ...,  122,  114,   85],\n",
       "         [  10,  118,   12,  ...,    6,   15,   69],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = train_dataloader._get_iterator()\n",
    "\n",
    "it._next_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.950125Z",
     "iopub.status.busy": "2023-10-30T15:46:07.949851Z",
     "iopub.status.idle": "2023-10-30T15:46:07.967626Z",
     "shell.execute_reply": "2023-10-30T15:46:07.966641Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.950101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Add positional encoding\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size: int, dropout: float, max_size: int = MAX_SIZE):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(\n",
    "            -torch.arange(0, embedding_size, 2) * math.log(10000) / embedding_size\n",
    "        )\n",
    "        pos = torch.arange(0, max_size).reshape(max_size, 1)\n",
    "        pos_embedding = torch.zeros((max_size, embedding_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(\n",
    "            token_embedding + self.pos_embedding[: token_embedding.size(0), :]\n",
    "        )\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    \"\"\"Learn embedding\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, embedding_size: int):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.embedding_size)\n",
    "\n",
    "\n",
    "class DetoxTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        embedding_size: int,\n",
    "        num_heads: int,\n",
    "        vocab_size: int,\n",
    "        feedforward_dim: int,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super(DetoxTransformer, self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(embedding_size, dropout=dropout)\n",
    "        self.input_embeddings = TokenEmbedding(vocab_size, embedding_size)\n",
    "        self.output_embeddings = TokenEmbedding(vocab_size, embedding_size)\n",
    "        self.transformer = Transformer(\n",
    "            d_model=embedding_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=feedforward_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: Tensor,\n",
    "        trg: Tensor,\n",
    "        src_mask: Tensor,\n",
    "        trg_mask: Tensor,\n",
    "        src_padding_mask: Tensor,\n",
    "        trg_padding_mask: Tensor,\n",
    "        memory_key_padding_mask: Tensor,\n",
    "    ):\n",
    "        src_embeddings = self.positional_encoding(self.input_embeddings(src))\n",
    "        trg_embeddings = self.positional_encoding(self.output_embeddings(trg))\n",
    "        outs = self.transformer(\n",
    "            src_embeddings,\n",
    "            trg_embeddings,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            None,\n",
    "            src_padding_mask,\n",
    "            trg_padding_mask,\n",
    "            memory_key_padding_mask,\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.input_embeddings(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, trg: Tensor, memory: Tensor, trg_mask: Tensor):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.output_embeddings(trg)), memory, trg_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.969020Z",
     "iopub.status.busy": "2023-10-30T15:46:07.968756Z",
     "iopub.status.idle": "2023-10-30T15:46:07.983226Z",
     "shell.execute_reply": "2023-10-30T15:46:07.982432Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.968997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(size: int) -> torch.Tensor:\n",
    "    mask = (torch.triu(torch.ones((size, size), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(toxic, nontoxic):\n",
    "    toxic_len = toxic.shape[0]\n",
    "    nontoxic_len = nontoxic.shape[0]\n",
    "\n",
    "    trg_mask = generate_square_subsequent_mask(nontoxic_len)\n",
    "    src_mask = torch.zeros((toxic_len, toxic_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    trg_padding_mask = (nontoxic == PAD_IDX).transpose(0, 1)\n",
    "    src_padding_mask = (toxic == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, trg_mask, src_padding_mask, trg_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:07.984402Z",
     "iopub.status.busy": "2023-10-30T15:46:07.984171Z",
     "iopub.status.idle": "2023-10-30T15:46:13.720917Z",
     "shell.execute_reply": "2023-10-30T15:46:13.719940Z",
     "shell.execute_reply.started": "2023-10-30T15:46:07.984381Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_square_subsequent_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:13.722557Z",
     "iopub.status.busy": "2023-10-30T15:46:13.722268Z",
     "iopub.status.idle": "2023-10-30T15:46:14.170700Z",
     "shell.execute_reply": "2023-10-30T15:46:14.169643Z",
     "shell.execute_reply.started": "2023-10-30T15:46:13.722526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "VOCAB_SIZE = len(dataset.vocab)\n",
    "\n",
    "EMB_SIZE = 320\n",
    "NUM_HEADS = 8\n",
    "FEED_FORWARD_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 4\n",
    "NUM_DECODER_LAYERS = 4\n",
    "\n",
    "model = DetoxTransformer(\n",
    "    NUM_ENCODER_LAYERS,\n",
    "    NUM_DECODER_LAYERS,\n",
    "    EMB_SIZE,\n",
    "    NUM_HEADS,\n",
    "    VOCAB_SIZE,\n",
    "    FEED_FORWARD_DIM,\n",
    ")\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:14.172208Z",
     "iopub.status.busy": "2023-10-30T15:46:14.171914Z",
     "iopub.status.idle": "2023-10-30T15:46:14.185601Z",
     "shell.execute_reply": "2023-10-30T15:46:14.184636Z",
     "shell.execute_reply.started": "2023-10-30T15:46:14.172183Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    for batch in loop:\n",
    "        toxic, nontoxic = batch\n",
    "        toxic, nontoxic = toxic.to(DEVICE), nontoxic.to(DEVICE)\n",
    "\n",
    "        nontoxic_input = nontoxic[:-1, :]\n",
    "\n",
    "        src_mask, trg_mask, src_padding_mask, trg_padding_mask = create_mask(\n",
    "            toxic, nontoxic_input\n",
    "        )\n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        outputs = model(\n",
    "            toxic,\n",
    "            nontoxic_input,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            src_padding_mask,\n",
    "            trg_padding_mask,\n",
    "            src_padding_mask,\n",
    "        )\n",
    "\n",
    "        nontoxic_out = nontoxic[1:, :]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, outputs.shape[-1]), nontoxic_out.reshape(-1))\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        total += nontoxic.size(0)\n",
    "\n",
    "        # optimizer run\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / total})\n",
    "\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        for batch in loop:\n",
    "            total += 1\n",
    "            toxic, nontoxic = batch\n",
    "\n",
    "            toxic, nontoxic = toxic.to(DEVICE), nontoxic.to(DEVICE)\n",
    "\n",
    "            nontoxic_input = nontoxic[:-1, :]\n",
    "\n",
    "            src_mask, trg_mask, src_padding_mask, trg_padding_mask = create_mask(\n",
    "                toxic, nontoxic_input\n",
    "            )\n",
    "\n",
    "            outputs = model(\n",
    "                toxic,\n",
    "                nontoxic_input,\n",
    "                src_mask,\n",
    "                trg_mask,\n",
    "                src_padding_mask,\n",
    "                trg_padding_mask,\n",
    "                src_padding_mask,\n",
    "            )\n",
    "\n",
    "            nontoxic_out = nontoxic[1:, :]\n",
    "\n",
    "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), nontoxic_out.reshape(-1))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            loop.set_postfix({\"loss\": val_loss / total})\n",
    "    return val_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T15:46:14.357029Z",
     "iopub.status.busy": "2023-10-30T15:46:14.356687Z",
     "iopub.status.idle": "2023-10-30T16:00:30.509074Z",
     "shell.execute_reply": "2023-10-30T16:00:30.508269Z",
     "shell.execute_reply.started": "2023-10-30T15:46:14.356996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: train: 100%|██████████| 212/212 [00:33<00:00,  6.28it/s, loss=0.185]\n",
      "Epoch 1: val: 100%|██████████| 12/12 [00:00<00:00, 20.04it/s, loss=5.09]\n",
      "Epoch 2: train: 100%|██████████| 212/212 [00:31<00:00,  6.72it/s, loss=0.137]\n",
      "Epoch 2: val: 100%|██████████| 12/12 [00:00<00:00, 19.85it/s, loss=4.28]\n",
      "Epoch 3: train: 100%|██████████| 212/212 [00:32<00:00,  6.54it/s, loss=0.118]\n",
      "Epoch 3: val: 100%|██████████| 12/12 [00:00<00:00, 19.58it/s, loss=3.85]\n",
      "Epoch 4: train: 100%|██████████| 212/212 [00:32<00:00,  6.45it/s, loss=0.107]\n",
      "Epoch 4: val: 100%|██████████| 12/12 [00:00<00:00, 18.73it/s, loss=3.55]\n",
      "Epoch 5: train: 100%|██████████| 212/212 [00:33<00:00,  6.31it/s, loss=0.0971]\n",
      "Epoch 5: val: 100%|██████████| 12/12 [00:00<00:00, 18.90it/s, loss=3.31]\n",
      "Epoch 6: train: 100%|██████████| 212/212 [00:33<00:00,  6.33it/s, loss=0.0897]\n",
      "Epoch 6: val: 100%|██████████| 12/12 [00:00<00:00, 19.04it/s, loss=3.13]\n",
      "Epoch 7: train: 100%|██████████| 212/212 [00:33<00:00,  6.30it/s, loss=0.0829]\n",
      "Epoch 7: val: 100%|██████████| 12/12 [00:00<00:00, 19.01it/s, loss=3.01]\n",
      "Epoch 8: train: 100%|██████████| 212/212 [00:33<00:00,  6.32it/s, loss=0.0781]\n",
      "Epoch 8: val: 100%|██████████| 12/12 [00:00<00:00, 12.82it/s, loss=2.9]\n",
      "Epoch 9: train: 100%|██████████| 212/212 [00:33<00:00,  6.32it/s, loss=0.0734]\n",
      "Epoch 9: val: 100%|██████████| 12/12 [00:00<00:00, 19.12it/s, loss=2.82]\n",
      "Epoch 10: train: 100%|██████████| 212/212 [00:33<00:00,  6.36it/s, loss=0.0694]\n",
      "Epoch 10: val: 100%|██████████| 12/12 [00:00<00:00, 19.00it/s, loss=2.75]\n",
      "Epoch 11: train: 100%|██████████| 212/212 [00:33<00:00,  6.36it/s, loss=0.0659]\n",
      "Epoch 11: val: 100%|██████████| 12/12 [00:00<00:00, 18.52it/s, loss=2.69]\n",
      "Epoch 12: train: 100%|██████████| 212/212 [00:33<00:00,  6.28it/s, loss=0.0615]\n",
      "Epoch 12: val: 100%|██████████| 12/12 [00:00<00:00, 19.04it/s, loss=2.64]\n",
      "Epoch 13: train: 100%|██████████| 212/212 [00:33<00:00,  6.34it/s, loss=0.0591]\n",
      "Epoch 13: val: 100%|██████████| 12/12 [00:00<00:00, 18.79it/s, loss=2.59]\n",
      "Epoch 14: train: 100%|██████████| 212/212 [00:33<00:00,  6.29it/s, loss=0.0558]\n",
      "Epoch 14: val: 100%|██████████| 12/12 [00:00<00:00, 19.22it/s, loss=2.56]\n",
      "Epoch 15: train: 100%|██████████| 212/212 [00:33<00:00,  6.30it/s, loss=0.0531]\n",
      "Epoch 15: val: 100%|██████████| 12/12 [00:00<00:00, 18.92it/s, loss=2.53]\n",
      "Epoch 16: train: 100%|██████████| 212/212 [00:33<00:00,  6.34it/s, loss=0.0508]\n",
      "Epoch 16: val: 100%|██████████| 12/12 [00:00<00:00, 19.17it/s, loss=2.51]\n",
      "Epoch 17: train: 100%|██████████| 212/212 [00:33<00:00,  6.36it/s, loss=0.0484]\n",
      "Epoch 17: val: 100%|██████████| 12/12 [00:00<00:00, 18.89it/s, loss=2.49]\n",
      "Epoch 18: train: 100%|██████████| 212/212 [00:33<00:00,  6.30it/s, loss=0.0454]\n",
      "Epoch 18: val: 100%|██████████| 12/12 [00:00<00:00, 19.33it/s, loss=2.49]\n",
      "Epoch 19: train: 100%|██████████| 212/212 [00:33<00:00,  6.24it/s, loss=0.0434]\n",
      "Epoch 19: val: 100%|██████████| 12/12 [00:00<00:00, 19.06it/s, loss=2.48]\n",
      "Epoch 20: train: 100%|██████████| 212/212 [00:33<00:00,  6.34it/s, loss=0.0416]\n",
      "Epoch 20: val: 100%|██████████| 12/12 [00:00<00:00, 18.97it/s, loss=2.47]\n",
      "Epoch 21: train: 100%|██████████| 212/212 [00:33<00:00,  6.33it/s, loss=0.0397]\n",
      "Epoch 21: val: 100%|██████████| 12/12 [00:00<00:00, 18.96it/s, loss=2.46]\n",
      "Epoch 22: train: 100%|██████████| 212/212 [00:33<00:00,  6.32it/s, loss=0.0377]\n",
      "Epoch 22: val: 100%|██████████| 12/12 [00:00<00:00, 18.98it/s, loss=2.45]\n",
      "Epoch 23: train: 100%|██████████| 212/212 [00:33<00:00,  6.33it/s, loss=0.036] \n",
      "Epoch 23: val: 100%|██████████| 12/12 [00:00<00:00, 18.83it/s, loss=2.45]\n",
      "Epoch 24: train: 100%|██████████| 212/212 [00:33<00:00,  6.37it/s, loss=0.0347]\n",
      "Epoch 24: val: 100%|██████████| 12/12 [00:00<00:00, 18.99it/s, loss=2.46]\n",
      "Epoch 25: train: 100%|██████████| 212/212 [00:33<00:00,  6.36it/s, loss=0.0328]\n",
      "Epoch 25: val: 100%|██████████| 12/12 [00:00<00:00, 18.75it/s, loss=2.45]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "best_loss = 1e10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    val_loss = val_one_epoch(model, val_dataloader, loss_fn, epoch)\n",
    "    if val_loss <= best_loss:\n",
    "        val_loss = best_loss\n",
    "        torch.save(model, \"../models/custom_transformer\")\n",
    "\n",
    "\n",
    "best = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.510782Z",
     "iopub.status.busy": "2023-10-30T16:00:30.510404Z",
     "iopub.status.idle": "2023-10-30T16:00:30.592431Z",
     "shell.execute_reply": "2023-10-30T16:00:30.591458Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.510749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetoxTransformer(\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (input_embeddings): TokenEmbedding(\n",
       "    (embedding): Embedding(14747, 320)\n",
       "  )\n",
       "  (output_embeddings): TokenEmbedding(\n",
       "    (embedding): Embedding(14747, 320)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=320, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=320, bias=True)\n",
       "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-3): 4 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=320, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=512, out_features=320, bias=True)\n",
       "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=320, out_features=14747, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"../models/custom_transformer\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.594167Z",
     "iopub.status.busy": "2023-10-30T16:00:30.593792Z",
     "iopub.status.idle": "2023-10-30T16:00:30.601298Z",
     "shell.execute_reply": "2023-10-30T16:00:30.600267Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.594133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess_text(text: str, vocab=dataset.vocab) -> torch.Tensor:\n",
    "    return torch.tensor([BOS_IDX] + vocab(TOKENIZER(text.lower())) + [EOS_IDX])\n",
    "\n",
    "\n",
    "def decode_tokens(tokens: torch.Tensor, vocab=dataset.vocab) -> str:\n",
    "    text = (\n",
    "        \" \".join(vocab.lookup_tokens(list(tokens.cpu().numpy())))\n",
    "        .replace(\"<bos>\", \"\")\n",
    "        .replace(\"<eos>\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    return re.sub(\" +\", \" \", re.sub(r'\\s([?.!\"](?:\\s|$))', r\"\\1\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.602855Z",
     "iopub.status.busy": "2023-10-30T16:00:30.602541Z",
     "iopub.status.idle": "2023-10-30T16:00:30.614496Z",
     "shell.execute_reply": "2023-10-30T16:00:30.613626Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.602830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def greedy_decode(\n",
    "    model: torch.nn.Module,\n",
    "    src: torch.Tensor,\n",
    "    src_mask: torch.Tensor,\n",
    "    max_size: int,\n",
    "    start_symbol: int,\n",
    ") -> torch.Tensor:\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    answer = torch.ones(1, 1).fill_(start_symbol).long().to(DEVICE)\n",
    "    for _ in range(max_size - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "\n",
    "        trg_mask = (generate_square_subsequent_mask(answer.size(0)).bool()).to(DEVICE)\n",
    "        outputs = model.decode(answer, memory, trg_mask)\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "\n",
    "        probabilities = model.generator(outputs[:, -1])\n",
    "        _, next_word = torch.max(probabilities, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        answer = torch.cat(\n",
    "            [answer, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return answer\n",
    "\n",
    "\n",
    "def detoxify(model: torch.nn.Module, src_sentence: str) -> str:\n",
    "    src = preprocess_text(src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    output_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_size=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    return decode_tokens(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:00:30.615983Z",
     "iopub.status.busy": "2023-10-30T16:00:30.615665Z",
     "iopub.status.idle": "2023-10-30T16:01:13.178242Z",
     "shell.execute_reply": "2023-10-30T16:01:13.177355Z",
     "shell.execute_reply.started": "2023-10-30T16:00:30.615944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:42<00:00, 11.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model_answers = []\n",
    "for i, r in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    model_answers.append(detoxify(model, r[\"toxic\"][:MAX_SIZE]))\n",
    "\n",
    "\n",
    "test_df[\"generated\"] = model_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:01:13.180102Z",
     "iopub.status.busy": "2023-10-30T16:01:13.179690Z",
     "iopub.status.idle": "2023-10-30T16:01:13.192022Z",
     "shell.execute_reply": "2023-10-30T16:01:13.190951Z",
     "shell.execute_reply.started": "2023-10-30T16:01:13.180054Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's feeding time at the fucking zoo!</td>\n",
       "      <td>it's time to eat at the zoo!</td>\n",
       "      <td>it 's about it and the floor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everyone here bet on the hero and lost their a...</td>\n",
       "      <td>they all took a hero and lost everything.</td>\n",
       "      <td>everyone 's here on your hero and all those th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then I got to come home to Melvin and his bull...</td>\n",
       "      <td>then I'm going home and Melvin's there.</td>\n",
       "      <td>then i have to come home and left his voice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sara here was hoping to pick your brains.</td>\n",
       "      <td>Sara was hoping you could handle her.</td>\n",
       "      <td>there was here i was hoping i 'd pick you your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, that's stupid. If anyone wants to tell me ...</td>\n",
       "      <td>if anyone wants to tell me what's going on, I'...</td>\n",
       "      <td>if anyone wants me to tell me what 's going on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               toxic  \\\n",
       "0              It's feeding time at the fucking zoo!   \n",
       "1  Everyone here bet on the hero and lost their a...   \n",
       "2  Then I got to come home to Melvin and his bull...   \n",
       "3          Sara here was hoping to pick your brains.   \n",
       "4  Oh, that's stupid. If anyone wants to tell me ...   \n",
       "\n",
       "                                            nontoxic  \\\n",
       "0                       it's time to eat at the zoo!   \n",
       "1          they all took a hero and lost everything.   \n",
       "2            then I'm going home and Melvin's there.   \n",
       "3              Sara was hoping you could handle her.   \n",
       "4  if anyone wants to tell me what's going on, I'...   \n",
       "\n",
       "                                           generated  \n",
       "0                      it 's about it and the floor.  \n",
       "1  everyone 's here on your hero and all those th...  \n",
       "2       then i have to come home and left his voice.  \n",
       "3  there was here i was hoping i 'd pick you your...  \n",
       "4  if anyone wants me to tell me what 's going on...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T16:01:13.193675Z",
     "iopub.status.busy": "2023-10-30T16:01:13.193349Z",
     "iopub.status.idle": "2023-10-30T16:01:13.211273Z",
     "shell.execute_reply": "2023-10-30T16:01:13.210526Z",
     "shell.execute_reply.started": "2023-10-30T16:01:13.193649Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../data/generated/custom_transformer.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
