{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text detoxification using Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import random_split\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_SEED = 42\n",
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df)=9462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I like that shit.</td>\n",
       "      <td>I love it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now, I understand you got your grievances with...</td>\n",
       "      <td>I understand you don't have to cut your bills,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Damn It!</td>\n",
       "      <td>oh, my God.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Help me, you cunt!</td>\n",
       "      <td>Aitchi, help me!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look at that shit.</td>\n",
       "      <td>look at this.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               toxic  \\\n",
       "0                                  I like that shit.   \n",
       "1  Now, I understand you got your grievances with...   \n",
       "2                                           Damn It!   \n",
       "3                                 Help me, you cunt!   \n",
       "4                                 Look at that shit.   \n",
       "\n",
       "                                            nontoxic  \n",
       "0                                         I love it.  \n",
       "1  I understand you don't have to cut your bills,...  \n",
       "2                                        oh, my God.  \n",
       "3                                   Aitchi, help me!  \n",
       "4                                      look at this.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('/content/drive/MyDrive/pmldl1_datasets/dataset_xs.csv')\n",
    "df = pd.read_csv(\"../data/raw/dataset_xs.csv\")\n",
    "print(f\"{len(df)=}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "SPECIAL_SYMBOLS = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "\n",
    "TOKENIZER = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetoxificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self._preprocess()\n",
    "        self._create_vocab()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        # Clean columns\n",
    "        self.df[\"toxic\"] = self.df[\"toxic\"].str.lower()\n",
    "        self.df[\"nontoxic\"] = self.df[\"nontoxic\"].str.lower()\n",
    "\n",
    "        # Tokenize sentences\n",
    "        self.toxic = self.df[\"toxic\"].apply(TOKENIZER).to_list()\n",
    "        self.nontoxic = self.df[\"nontoxic\"].apply(TOKENIZER).to_list()\n",
    "\n",
    "        self.data = self.toxic + self.nontoxic\n",
    "\n",
    "    def _create_vocab(self):\n",
    "        self.vocab = build_vocab_from_iterator(\n",
    "            self.data,\n",
    "            min_freq=1,\n",
    "            specials=SPECIAL_SYMBOLS,\n",
    "            special_first=True,\n",
    "        )\n",
    "        self.vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "    def _get_toxic(self, index: int) -> list:\n",
    "        text = self.toxic[index]\n",
    "        return [BOS_IDX] + self.vocab(text) + [EOS_IDX]\n",
    "\n",
    "    def _get_nontoxic(self, index: int) -> list:\n",
    "        text = self.nontoxic[index]\n",
    "        return [BOS_IDX] + self.vocab(text) + [EOS_IDX]\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[list, list]:\n",
    "        return self._get_toxic(index), self._get_nontoxic(index)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DetoxificationDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset)=8043\n",
      "len(val_dataset)=946\n",
      "len(test_dataset)=473\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [0.85, 0.1, 0.05], generator=torch.Generator().manual_seed(MANUAL_SEED)\n",
    ")\n",
    "print(f\"{len(train_dataset)=}\")\n",
    "print(f\"{len(val_dataset)=}\")\n",
    "print(f\"{len(test_dataset)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_SIZE = 50\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch: list) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    toxic_batch, nontoxic_batch = [], []\n",
    "    for _toxic, _nontoxic in batch:\n",
    "        _toxic_tensor = torch.Tensor(_toxic)\n",
    "        _nontoxic_tensor = torch.Tensor(_nontoxic)\n",
    "\n",
    "        toxic_batch.append(_toxic_tensor[:MAX_SIZE])\n",
    "        nontoxic_batch.append(_nontoxic_tensor[:MAX_SIZE])\n",
    "\n",
    "    toxic_batch = pad_sequence(toxic_batch, padding_value=PAD_IDX)\n",
    "    nontoxic_batch = pad_sequence(nontoxic_batch, padding_value=PAD_IDX)\n",
    "\n",
    "    return toxic_batch.long(), nontoxic_batch.long()\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Add positional encoding\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_size: int, dropout: float, max_size: int = MAX_SIZE):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(\n",
    "            -torch.arange(0, embedding_size, 2) * math.log(10000) / embedding_size\n",
    "        )\n",
    "        pos = torch.arange(0, max_size).reshape(max_size, 1)\n",
    "        pos_embedding = torch.zeros((max_size, embedding_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(\n",
    "            token_embedding + self.pos_embedding[: token_embedding.size(0), :]\n",
    "        )\n",
    "\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    \"\"\"Learn embedding\"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size: int, embedding_size: int):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.embedding_size)\n",
    "\n",
    "\n",
    "class DetoxTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_encoder_layers: int,\n",
    "        num_decoder_layers: int,\n",
    "        embedding_size: int,\n",
    "        num_heads: int,\n",
    "        vocab_size: int,\n",
    "        feedforward_dim: int,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super(DetoxTransformer, self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(embedding_size, dropout=dropout)\n",
    "        self.input_embeddings = TokenEmbedding(vocab_size, embedding_size)\n",
    "        self.output_embeddings = TokenEmbedding(vocab_size, embedding_size)\n",
    "        self.transformer = Transformer(\n",
    "            d_model=embedding_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=feedforward_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.generator = nn.Linear(embedding_size, vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: Tensor,\n",
    "        trg: Tensor,\n",
    "        src_mask: Tensor,\n",
    "        trg_mask: Tensor,\n",
    "        src_padding_mask: Tensor,\n",
    "        trg_padding_mask: Tensor,\n",
    "        memory_key_padding_mask: Tensor,\n",
    "    ):\n",
    "        src_embeddings = self.positional_encoding(self.input_embeddings(src))\n",
    "        trg_embeddings = self.positional_encoding(self.output_embeddings(trg))\n",
    "        outs = self.transformer(\n",
    "            src_embeddings,\n",
    "            trg_embeddings,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            None,\n",
    "            src_padding_mask,\n",
    "            trg_padding_mask,\n",
    "            memory_key_padding_mask,\n",
    "        )\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(\n",
    "            self.positional_encoding(self.input_embeddings(src)), src_mask\n",
    "        )\n",
    "\n",
    "    def decode(self, trg: Tensor, memory: Tensor, trg_mask: Tensor):\n",
    "        return self.transformer.decoder(\n",
    "            self.positional_encoding(self.output_embeddings(trg)), memory, trg_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(size: int) -> torch.Tensor:\n",
    "    mask = (torch.triu(torch.ones((size, size), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(toxic, nontoxic):\n",
    "    toxic_len = toxic.shape[0]\n",
    "    nontoxic_len = nontoxic.shape[0]\n",
    "\n",
    "    trg_mask = generate_square_subsequent_mask(nontoxic_len)\n",
    "    src_mask = torch.zeros((toxic_len, toxic_len), device=DEVICE).type(torch.bool)\n",
    "\n",
    "    trg_padding_mask = (nontoxic == PAD_IDX).transpose(0, 1)\n",
    "    src_padding_mask = (toxic == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, trg_mask, src_padding_mask, trg_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf],\n",
       "        [0., 0., -inf],\n",
       "        [0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_square_subsequent_mask(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(MANUAL_SEED)\n",
    "\n",
    "VOCAB_SIZE = len(dataset.vocab)\n",
    "EMB_SIZE = 128\n",
    "NUM_HEADS = 2\n",
    "FEED_FORWARD_DIM = 128\n",
    "NUM_ENCODER_LAYERS = 1\n",
    "NUM_DECODER_LAYERS = 1\n",
    "\n",
    "model = DetoxTransformer(\n",
    "    NUM_ENCODER_LAYERS,\n",
    "    NUM_DECODER_LAYERS,\n",
    "    EMB_SIZE,\n",
    "    NUM_HEADS,\n",
    "    VOCAB_SIZE,\n",
    "    FEED_FORWARD_DIM,\n",
    ")\n",
    "\n",
    "# initialize model parameters\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: train\",\n",
    "        leave=True,\n",
    "    )\n",
    "    for batch in loop:\n",
    "        toxic, nontoxic = batch\n",
    "\n",
    "        toxic, nontoxic = toxic.to(DEVICE), nontoxic.to(DEVICE)\n",
    "\n",
    "        src_mask, trg_mask, src_padding_mask, trg_padding_mask = create_mask(\n",
    "            toxic, nontoxic\n",
    "        )\n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        outputs = model(\n",
    "            toxic,\n",
    "            nontoxic,\n",
    "            src_mask,\n",
    "            trg_mask,\n",
    "            src_padding_mask,\n",
    "            trg_padding_mask,\n",
    "            src_padding_mask,\n",
    "        )\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        nontoxic = nontoxic.reshape(-1)\n",
    "        loss = loss_fn(outputs, nontoxic)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        total += nontoxic.size(0)\n",
    "\n",
    "        # optimizer run\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        loop.set_postfix({\"loss\": train_loss / total})\n",
    "\n",
    "\n",
    "def val_one_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    loss_fn,\n",
    "    epoch,\n",
    "):\n",
    "    loop = tqdm(\n",
    "        loader,\n",
    "        total=len(loader),\n",
    "        desc=f\"Epoch {epoch}: val\",\n",
    "        leave=True,\n",
    "    )\n",
    "    val_loss = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # evaluation mode\n",
    "        for batch in loop:\n",
    "            total += 1\n",
    "            toxic, nontoxic = batch\n",
    "\n",
    "            toxic, nontoxic = toxic.to(DEVICE), nontoxic.to(DEVICE)\n",
    "\n",
    "            src_mask, trg_mask, src_padding_mask, trg_padding_mask = create_mask(\n",
    "                toxic, nontoxic\n",
    "            )\n",
    "\n",
    "            outputs = model(\n",
    "                toxic,\n",
    "                nontoxic,\n",
    "                src_mask,\n",
    "                trg_mask,\n",
    "                src_padding_mask,\n",
    "                trg_padding_mask,\n",
    "                src_padding_mask,\n",
    "            )\n",
    "\n",
    "            outputs = outputs.view(-1, outputs.shape[-1])\n",
    "            nontoxic = nontoxic.reshape(-1)\n",
    "\n",
    "            loss = loss_fn(outputs, nontoxic)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            loop.set_postfix({\"loss\": val_loss / total})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    # torch.cuda.empty_cache()\n",
    "    train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    val_one_epoch(model, val_dataloader, loss_fn, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"./models/custom_transformer\")\n",
    "torch.save(model, \"../models/custom_transformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetoxTransformer(\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (input_embeddings): TokenEmbedding(\n",
       "    (embedding): Embedding(6538, 128)\n",
       "  )\n",
       "  (output_embeddings): TokenEmbedding(\n",
       "    (embedding): Embedding(6538, 128)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=128, out_features=6538, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = torch.load(\"./models/custom_transformer\")\n",
    "model = torch.load(\"../models/custom_transformer\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, vocab=dataset.vocab) -> torch.Tensor:\n",
    "    return torch.tensor([BOS_IDX] + vocab(TOKENIZER(text.lower())) + [EOS_IDX])\n",
    "\n",
    "\n",
    "def decode_tokens(tokens: torch.Tensor, vocab=dataset.vocab) -> str:\n",
    "    return (\n",
    "        \" \".join(vocab.lookup_tokens(list(tokens.cpu().numpy())))\n",
    "        .replace(\"<bos>\", \"\")\n",
    "        .replace(\"<eos>\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(\n",
    "    model: torch.nn.Module,\n",
    "    src: torch.Tensor,\n",
    "    src_mask: torch.Tensor,\n",
    "    max_size: int,\n",
    "    start_symbol: int,\n",
    ") -> torch.Tensor:\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    answer = torch.ones(1, 1).fill_(start_symbol).long().to(DEVICE)\n",
    "    for _ in range(max_size - 1):\n",
    "        memory = memory.to(DEVICE)\n",
    "\n",
    "        trg_mask = (generate_square_subsequent_mask(answer.size(0)).bool()).to(DEVICE)\n",
    "        outputs = model.decode(answer, memory, trg_mask)\n",
    "        outputs = outputs.transpose(0, 1)\n",
    "\n",
    "        probabilities = model.generator(outputs[:, -1])\n",
    "        _, next_word = torch.max(probabilities, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        answer = torch.cat(\n",
    "            [answer, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0\n",
    "        )\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return answer\n",
    "\n",
    "\n",
    "def detoxify(model: torch.nn.Module, src_sentence: str) -> str:\n",
    "    model.eval()\n",
    "    src = preprocess_text(src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    output_tokens = greedy_decode(\n",
    "        model, src, src_mask, max_size=num_tokens + 5, start_symbol=BOS_IDX\n",
    "    ).flatten()\n",
    "    return decode_tokens(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>you know how the romans settled this shit?</td>\n",
       "      <td>do you know how the romans handled this?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>what kind of shit do you talk?</td>\n",
       "      <td>what are you talking about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>idiot. there's a storage shed near the back.</td>\n",
       "      <td>there's a warehouse in the back.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>come get her! goddamn you!</td>\n",
       "      <td>come and get her!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>you fucker hello, post office?</td>\n",
       "      <td>hello, post office?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             toxic  \\\n",
       "7898    you know how the romans settled this shit?   \n",
       "5283                what kind of shit do you talk?   \n",
       "6611  idiot. there's a storage shed near the back.   \n",
       "3187                    come get her! goddamn you!   \n",
       "8466                you fucker hello, post office?   \n",
       "\n",
       "                                      nontoxic  \n",
       "7898  do you know how the romans handled this?  \n",
       "5283               what are you talking about?  \n",
       "6611          there's a warehouse in the back.  \n",
       "3187                         come and get her!  \n",
       "8466                       hello, post office?  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices = list(test_dataset.indices)\n",
    "\n",
    "test_df = df.iloc[test_indices]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [00:25<00:00, 18.71it/s]\n"
     ]
    }
   ],
   "source": [
    "model_answers = []\n",
    "for i, r in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    model_answers.append(detoxify(model, r[\"toxic\"]))\n",
    "\n",
    "\n",
    "test_df[\"generated\"] = model_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>nontoxic</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>you know how the romans settled this shit?</td>\n",
       "      <td>do you know how the romans handled this?</td>\n",
       "      <td>bootleggin captain bootleggin bootleggin boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5283</th>\n",
       "      <td>what kind of shit do you talk?</td>\n",
       "      <td>what are you talking about?</td>\n",
       "      <td>bootleggin bootleggin bootleggin bootleggin b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>idiot. there's a storage shed near the back.</td>\n",
       "      <td>there's a warehouse in the back.</td>\n",
       "      <td>bootleggin bootleggin bootleggin bootleggin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>come get her! goddamn you!</td>\n",
       "      <td>come and get her!</td>\n",
       "      <td>bootleggin captain bootleggin burset bootlegg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>you fucker hello, post office?</td>\n",
       "      <td>hello, post office?</td>\n",
       "      <td>bootleggin burset bootleggin bootleggin bootl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             toxic  \\\n",
       "7898    you know how the romans settled this shit?   \n",
       "5283                what kind of shit do you talk?   \n",
       "6611  idiot. there's a storage shed near the back.   \n",
       "3187                    come get her! goddamn you!   \n",
       "8466                you fucker hello, post office?   \n",
       "\n",
       "                                      nontoxic  \\\n",
       "7898  do you know how the romans handled this?   \n",
       "5283               what are you talking about?   \n",
       "6611          there's a warehouse in the back.   \n",
       "3187                         come and get her!   \n",
       "8466                       hello, post office?   \n",
       "\n",
       "                                              generated  \n",
       "7898   bootleggin captain bootleggin bootleggin boot...  \n",
       "5283   bootleggin bootleggin bootleggin bootleggin b...  \n",
       "6611   bootleggin bootleggin bootleggin bootleggin o...  \n",
       "3187   bootleggin captain bootleggin burset bootlegg...  \n",
       "8466   bootleggin burset bootleggin bootleggin bootl...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.to_csv(\"./transformer.csv\", index=False)\n",
    "test_df.to_csv(\"../data/generated/custom_transformer.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text-detoxification-hSirkgjj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
