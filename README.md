# Text Detoxification

by Dmitry Beresnev
IU F23 / B20-AI / <d.beresnev@innopolis.university>

## Introduction

This repository is the solution for Assignment 1 of Practical Machine Learning and Deep Learning F23 IU course

## Requirements

Code was tested on Windows 11, Python 3.11 and CUDA 11.8.

All the requirement packages are listed in the file `requirements.txt`. In case you use the `pipenv` package, there is also `Pipfile` in the root of the project.

## Before start

Install all the packages from _requirements.txt_ using `pip install -r requirements.txt` or using **pipenv** `pipenv install`.

Optionally, you can run `bash setup_precommit.sh` to setup pre-commit hook for GitHub for code formatting using [ruff](https://docs.astral.sh/ruff/).

I also highly recommend to read reports in corresponding `reports` folder to fully understand context and purpose of some files and folders.

## Repository structure

```text
├── README.md       # The top-level README
│
├── data
│   ├── external    # Data from third party sources
│   ├── figures     # Plots and other visualized data in .svg format
│   ├── generated   # Data generated by models and other scripts
|   |   ├── bart.csv
|   |   ├── custom_transformer.csv
|   |   └── metrics.csv
|   |
│   ├── interim     # Intermediate data that has been transformed
│   └── raw         # The original, immutable data. Collected via src/mak_dataset.py script
|       ├── dataset_lg.csv
|       ├── dataset_md.csv
|       ├── dataset_sm.csv
|       ├── dataset_xs.csv
|       └── test.csv
│
├── models          # Trained and serialized models, final checkpoints
│   ├── bart
│   ├── train_data  # Intermediate HuggingFace Trainer data
│   ├── bart.md     # Reference to fine-tuned BART on Hugging Face
│   ├── custom_transformer
│   └── custom_transformer_vocab.pth
│
├── notebooks       #  Jupyter notebooks
│   ├── 1.0-initial-data-exploration.ipynb
│   ├── 2.0-torchtext-transformer.ipynb
│   ├── 3.0-finetunning-bart.ipynb
│   └── 4.0-metrics.ipynb
│
├── references      # Data dictionaries, manuals, and all other explanatory materials
│
├── reports         # Generated analysis as HTML, PDF, LaTeX, etc.
│   └── figures     # Generated graphics and figures to be used in reporting
│
├── requirements.txt  # The requirements file for reproducing the analysis environment
│                      generated with pip freeze › requirements. txt'
|
└── src                 # Source code for use in this assignment
|    │
|    ├── data            # Scripts to download or generate data
|    │   └── make_dataset.py
|    │
|    ├── models          # Scripts to train models and then use trained models to make |predictions
|    │   ├── predict_model.py
|    │   └── train_model.py
|    │
|    └── visualization   # Scripts to create exploratory and results oriented |visualizations
|        └── visualize.py
|
├── AssignmentDescription.md # Description of the task
├── Pipfile         # File with dependencies for pipenv
├── pyproject.toml  # Formatter and linter settings
└── setup_precommit.sh  # Script for creating pre-commit GitHub hook
```

## Basic usage

This section describes how to use scripts from `src/` folder.

For all scripts help messages are available with `-h` flag. For example, `python ./src/data/make_dataset.py -h` explains all the available flags and their purpose. Generally, for all scripts two modes are available: verbose and non-verbose. By default verbose mode is active, and to run the script in silent mode you need the `--no-verbose` flag.

For all scripts inside `./src/models` two models are available: **bart** (fine-tunned BART) and **custom_transformer** (custom torchtext Transformer). Note that for `./src/models/predict_model.py` also interactive mode is available: to turn it on use the `-i` flag. For more information, please read corresponding help messages.

Generally, I highly recommend to always read the help messages before using scripts.

## References

### Models

- [Initial BART on Hugging Face](https://huggingface.co/eugenesiow/bart-paraphrase)
- [Fine-tuned BART on Hugging Face](https://huggingface.co/dsomni/pmldl1-bart)

### Metrics

- [Toxicity](https://huggingface.co/spaces/evaluate-measurement/toxicity)
- [ROUGE](https://huggingface.co/spaces/evaluate-metric/rouge)
- [WER](https://huggingface.co/spaces/evaluate-metric/wer)
- [BLEU](https://huggingface.co/spaces/evaluate-metric/bleu)
- [METEOR](https://huggingface.co/spaces/evaluate-metric/meteor)

### Documentations & Tutorials

- [PyTorch + torchtext transformer tutorial](https://pytorch.org/tutorials/beginner/translation_transformer.html)
- [Hugging Face fine-tunning tutorial](https://huggingface.co/docs/transformers/training)

## Contacts

In case of any questions you can contact me via email <d.beresnev@innopolis.university> or Telegram **@d.flip.floppa**
